{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-02T11:16:47.702467Z",
     "iopub.status.busy": "2025-11-02T11:16:47.702287Z",
     "iopub.status.idle": "2025-11-02T11:16:48.747381Z",
     "shell.execute_reply": "2025-11-02T11:16:48.746665Z",
     "shell.execute_reply.started": "2025-11-02T11:16:47.702451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-11-02T11:16:48.749300Z",
     "iopub.status.busy": "2025-11-02T11:16:48.748913Z",
     "iopub.status.idle": "2025-11-02T11:18:11.980488Z",
     "shell.execute_reply": "2025-11-02T11:18:11.979593Z",
     "shell.execute_reply.started": "2025-11-02T11:16:48.749276Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Shannu3766/Cosine-similarity.git\n",
      "  Cloning https://github.com/Shannu3766/Cosine-similarity.git to /tmp/pip-req-build-dqm56dyi\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/Shannu3766/Cosine-similarity.git /tmp/pip-req-build-dqm56dyi\n",
      "  Resolved https://github.com/Shannu3766/Cosine-similarity.git to commit b48108caf5ac80365a8ed4380ac2fe3f830210cf\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from adalora_bi_eq13==0.1.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from adalora_bi_eq13==0.1.0) (4.53.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from adalora_bi_eq13==0.1.0) (4.1.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from adalora_bi_eq13==0.1.0) (4.67.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from adalora_bi_eq13==0.1.0) (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->adalora_bi_eq13==0.1.0) (3.19.1)\n",
      "Collecting pyarrow>=21.0.0 (from datasets->adalora_bi_eq13==0.1.0)\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->adalora_bi_eq13==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->adalora_bi_eq13==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->adalora_bi_eq13==0.1.0) (2.32.5)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->adalora_bi_eq13==0.1.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->adalora_bi_eq13==0.1.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets->adalora_bi_eq13==0.1.0) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->adalora_bi_eq13==0.1.0) (1.0.0rc2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->adalora_bi_eq13==0.1.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->adalora_bi_eq13==0.1.0) (6.0.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->adalora_bi_eq13==0.1.0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->adalora_bi_eq13==0.1.0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->adalora_bi_eq13==0.1.0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->adalora_bi_eq13==0.1.0) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->adalora_bi_eq13==0.1.0) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->adalora_bi_eq13==0.1.0) (2.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->adalora_bi_eq13==0.1.0) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->adalora_bi_eq13==0.1.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->adalora_bi_eq13==0.1.0) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->adalora_bi_eq13==0.1.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->adalora_bi_eq13==0.1.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->adalora_bi_eq13==0.1.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->adalora_bi_eq13==0.1.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->adalora_bi_eq13==0.1.0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->adalora_bi_eq13==0.1.0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->adalora_bi_eq13==0.1.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->adalora_bi_eq13==0.1.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->adalora_bi_eq13==0.1.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->adalora_bi_eq13==0.1.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->adalora_bi_eq13==0.1.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->adalora_bi_eq13==0.1.0) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->adalora_bi_eq13==0.1.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->adalora_bi_eq13==0.1.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->adalora_bi_eq13==0.1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->adalora_bi_eq13==0.1.0) (1.3.0)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets->adalora_bi_eq13==0.1.0)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->adalora_bi_eq13==0.1.0) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->adalora_bi_eq13==0.1.0) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->adalora_bi_eq13==0.1.0) (0.5.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets->adalora_bi_eq13==0.1.0) (3.12.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets->adalora_bi_eq13==0.1.0) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->adalora_bi_eq13==0.1.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->adalora_bi_eq13==0.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->adalora_bi_eq13==0.1.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->adalora_bi_eq13==0.1.0) (2025.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->adalora_bi_eq13==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->adalora_bi_eq13==0.1.0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->adalora_bi_eq13==0.1.0) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->adalora_bi_eq13==0.1.0) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->adalora_bi_eq13==0.1.0) (2024.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->adalora_bi_eq13==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->adalora_bi_eq13==0.1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->adalora_bi_eq13==0.1.0) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->adalora_bi_eq13==0.1.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->adalora_bi_eq13==0.1.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->adalora_bi_eq13==0.1.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->adalora_bi_eq13==0.1.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->adalora_bi_eq13==0.1.0) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->adalora_bi_eq13==0.1.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->adalora_bi_eq13==0.1.0) (1.20.1)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->adalora_bi_eq13==0.1.0) (2024.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->adalora_bi_eq13==0.1.0) (1.17.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: adalora_bi_eq13\n",
      "  Building wheel for adalora_bi_eq13 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for adalora_bi_eq13: filename=adalora_bi_eq13-0.1.0-py3-none-any.whl size=6604 sha256=f2710679c4955dd100661619c663bf0bab80ca97fb7f2f6a759b6b86c956482b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-bn6ak07k/wheels/76/bb/9e/d30494391cfeaff12e87f494af145e11c56eaec39eff965930\n",
      "Successfully built adalora_bi_eq13\n",
      "Installing collected packages: pyarrow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, nvidia-cusolver-cu12, adalora_bi_eq13\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 1.0.0rc2\n",
      "    Uninstalling huggingface-hub-1.0.0rc2:\n",
      "      Successfully uninstalled huggingface-hub-1.0.0rc2\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed adalora_bi_eq13-0.1.0 huggingface-hub-0.36.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyarrow-22.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/Shannu3766/Cosine-similarity.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:18:11.981775Z",
     "iopub.status.busy": "2025-11-02T11:18:11.981477Z",
     "iopub.status.idle": "2025-11-02T11:18:19.486492Z",
     "shell.execute_reply": "2025-11-02T11:18:19.485778Z",
     "shell.execute_reply.started": "2025-11-02T11:18:11.981750Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -U \"pyarrow>=15.0.0\" \"datasets>=2.18.0\" --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:18:19.487718Z",
     "iopub.status.busy": "2025-11-02T11:18:19.487414Z",
     "iopub.status.idle": "2025-11-02T11:18:29.260201Z",
     "shell.execute_reply": "2025-11-02T11:18:29.259435Z",
     "shell.execute_reply.started": "2025-11-02T11:18:19.487684Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade pyarrow datasets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:18:29.261227Z",
     "iopub.status.busy": "2025-11-02T11:18:29.261037Z",
     "iopub.status.idle": "2025-11-02T11:18:38.526220Z",
     "shell.execute_reply": "2025-11-02T11:18:38.525532Z",
     "shell.execute_reply.started": "2025-11-02T11:18:29.261209Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow<17,>=14.0.1\n",
      "  Downloading pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting numpy>=1.16.6 (from pyarrow<17,>=14.0.1)\n",
      "  Downloading numpy-2.3.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading numpy-2.3.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, pyarrow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 22.0.0\n",
      "    Uninstalling pyarrow-22.0.0:\n",
      "      Successfully uninstalled pyarrow-22.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "datasets 4.3.0 requires pyarrow>=21.0.0, but you have pyarrow 16.1.0 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\n",
      "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.4 which is incompatible.\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.3.4 pyarrow-16.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall \"pyarrow>=14.0.1,<17\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:18:38.527381Z",
     "iopub.status.busy": "2025-11-02T11:18:38.527186Z",
     "iopub.status.idle": "2025-11-02T11:19:09.186929Z",
     "shell.execute_reply": "2025-11-02T11:19:09.186215Z",
     "shell.execute_reply.started": "2025-11-02T11:18:38.527362Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy<1.14,>=1.10\n",
      "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn<1.5,>=1.3\n",
      "  Downloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn<1.5,>=1.3)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn<1.5,>=1.3)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.6.0\n",
      "    Uninstalling threadpoolctl-3.6.0:\n",
      "      Successfully uninstalled threadpoolctl-3.6.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.4\n",
      "    Uninstalling numpy-2.3.4:\n",
      "      Successfully uninstalled numpy-2.3.4\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.5.2\n",
      "    Uninstalling joblib-1.5.2:\n",
      "      Successfully uninstalled joblib-1.5.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.3\n",
      "    Uninstalling scipy-1.15.3:\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "datasets 4.3.0 requires pyarrow>=21.0.0, but you have pyarrow 16.1.0 which is incompatible.\n",
      "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed joblib-1.5.2 numpy-1.26.4 scikit-learn-1.4.2 scipy-1.13.1 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall \"numpy<2.0\" \"scipy>=1.10,<1.14\" \"scikit-learn>=1.3,<1.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:19:09.189756Z",
     "iopub.status.busy": "2025-11-02T11:19:09.189528Z",
     "iopub.status.idle": "2025-11-02T11:19:09.194047Z",
     "shell.execute_reply": "2025-11-02T11:19:09.193325Z",
     "shell.execute_reply.started": "2025-11-02T11:19:09.189732Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.0.1\n"
     ]
    }
   ],
   "source": [
    "import pyarrow\n",
    "print(pyarrow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:19:09.195011Z",
     "iopub.status.busy": "2025-11-02T11:19:09.194749Z",
     "iopub.status.idle": "2025-11-02T11:19:16.653101Z",
     "shell.execute_reply": "2025-11-02T11:19:16.652404Z",
     "shell.execute_reply.started": "2025-11-02T11:19:09.194988Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U pyarrow==17.0.0 datasets==3.0.2 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:19:16.654463Z",
     "iopub.status.busy": "2025-11-02T11:19:16.654224Z",
     "iopub.status.idle": "2025-11-02T11:19:40.401463Z",
     "shell.execute_reply": "2025-11-02T11:19:40.400693Z",
     "shell.execute_reply.started": "2025-11-02T11:19:16.654442Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.ChunkedArray size changed, may indicate binary incompatibility. Expected 64 from C header, got 72 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib._Tabular size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Table size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "2025-11-02 11:19:28.747593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762082368.974909      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762082369.047482      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fine-tune DeepSeek-small for Question Answering using Adaptive LoRA (Eq.1.3).\n",
    "Reduced dataset (100 train + 100 validation) for quick testing on Kaggle T4x2.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    default_data_collator,\n",
    ")\n",
    "from adalora_bi_eq13 import fine_tune_lora_dynamic\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# ✅ Prepare the SQuAD-v2 dataset (100 samples only)\n",
    "# ---------------------------------------------------------------------------\n",
    "def prepare_squad(tokenizer, max_length=384, doc_stride=128):\n",
    "    \"\"\"Tokenize the SQuAD-v2 dataset safely for models without cls tokens (e.g., DeepSeek).\"\"\"\n",
    "    dataset = load_dataset(\"squad_v2\")\n",
    "\n",
    "    def preprocess(batch):\n",
    "        questions = [q.strip() for q in batch[\"question\"]]\n",
    "        inputs = tokenizer(\n",
    "            questions,\n",
    "            batch[\"context\"],\n",
    "            truncation=\"only_second\",\n",
    "            max_length=max_length,\n",
    "            stride=doc_stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "        sample_mapping = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "        offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "\n",
    "        start_positions, end_positions = [], []\n",
    "\n",
    "        for i, offsets in enumerate(offset_mapping):\n",
    "            input_ids = inputs[\"input_ids\"][i]\n",
    "            # fallback if CLS token doesn't exist\n",
    "            cls_token_id = tokenizer.cls_token_id or tokenizer.eos_token_id or input_ids[0]\n",
    "            if cls_token_id not in input_ids:\n",
    "                cls_index = 0\n",
    "            else:\n",
    "                cls_index = input_ids.index(cls_token_id)\n",
    "\n",
    "            sequence_ids = inputs.sequence_ids(i)\n",
    "            sample_idx = sample_mapping[i]\n",
    "            answers = batch[\"answers\"][sample_idx]\n",
    "\n",
    "            # No answer case\n",
    "            if len(answers[\"answer_start\"]) == 0:\n",
    "                start_positions.append(cls_index)\n",
    "                end_positions.append(cls_index)\n",
    "                continue\n",
    "\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # Find token span for answer\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != 1:\n",
    "                token_start_index += 1\n",
    "\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != 1:\n",
    "                token_end_index -= 1\n",
    "\n",
    "            if not (\n",
    "                offsets[token_start_index][0] <= start_char\n",
    "                and offsets[token_end_index][1] >= end_char\n",
    "            ):\n",
    "                start_positions.append(cls_index)\n",
    "                end_positions.append(cls_index)\n",
    "            else:\n",
    "                while (\n",
    "                    token_start_index < len(offsets)\n",
    "                    and offsets[token_start_index][0] <= start_char\n",
    "                ):\n",
    "                    token_start_index += 1\n",
    "                start_positions.append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                end_positions.append(token_end_index + 1)\n",
    "\n",
    "        inputs[\"start_positions\"] = start_positions\n",
    "        inputs[\"end_positions\"] = end_positions\n",
    "        return inputs\n",
    "\n",
    "    tokenized = dataset.map(\n",
    "        preprocess,\n",
    "        batched=True,\n",
    "        remove_columns=dataset[\"train\"].column_names,\n",
    "        desc=\"Tokenizing SQuAD-v2\",\n",
    "    )\n",
    "    print(len(tokenized[\"train\"]))\n",
    "    print(len(tokenized[\"validation\"]))\n",
    "    # ↓ use only 100 samples for quick testing\n",
    "    return tokenized[\"train\"].select(range(10000)), tokenized[\"validation\"].select(range(1000))\n",
    "    # return tokenized[\"train\"], tokenized[\"validation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:19:40.403300Z",
     "iopub.status.busy": "2025-11-02T11:19:40.402378Z",
     "iopub.status.idle": "2025-11-02T11:19:43.822065Z",
     "shell.execute_reply": "2025-11-02T11:19:43.821242Z",
     "shell.execute_reply.started": "2025-11-02T11:19:40.403273Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face login successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in 'login': write_permission. Will not be supported from version '1.0'.\n",
      "\n",
      "Fine-grained tokens added complexity to the permissions, making it irrelevant to check if a token has 'write' access.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# First, ensure the necessary libraries are installed\n",
    "!pip install huggingface_hub -q\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from huggingface_hub import login\n",
    "\n",
    "# 2. Log in to Hugging Face\n",
    "#    write_permission=True is needed if you want to upload models\n",
    "login(token=\"\", write_permission=True)\n",
    "\n",
    "print(\"Hugging Face login successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:19:43.823237Z",
     "iopub.status.busy": "2025-11-02T11:19:43.822979Z",
     "iopub.status.idle": "2025-11-02T11:19:43.894023Z",
     "shell.execute_reply": "2025-11-02T11:19:43.893108Z",
     "shell.execute_reply.started": "2025-11-02T11:19:43.823216Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:19:43.895485Z",
     "iopub.status.busy": "2025-11-02T11:19:43.895045Z",
     "iopub.status.idle": "2025-11-02T11:19:45.705319Z",
     "shell.execute_reply": "2025-11-02T11:19:45.704513Z",
     "shell.execute_reply.started": "2025-11-02T11:19:43.895455Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0058ff83c24f4f53a8a2b6ddf7f7f4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/793 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904256ac04134115b10d5cb571aaca56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858f1aa691904d188022ebaa693c6a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.cls_token is None:\n",
    "    tokenizer.add_special_tokens({\"cls_token\": \"<cls>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:19:45.706334Z",
     "iopub.status.busy": "2025-11-02T11:19:45.706127Z",
     "iopub.status.idle": "2025-11-02T11:21:10.730159Z",
     "shell.execute_reply": "2025-11-02T11:21:10.729379Z",
     "shell.execute_reply.started": "2025-11-02T11:19:45.706318Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing SQuAD-v2 dataset (100 samples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42333e77c424da3956450177ec84eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae59dcd72d2489b8c274a30531e1546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "squad_v2/train-00000-of-00001.parquet:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d4275b3f104515bd4499c82bb5c137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "squad_v2/validation-00000-of-00001.parqu(…):   0%|          | 0.00/1.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc1a196f3b44803abad3dd71e737225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369f92fce74c4d24902132280921481a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99b0a90512d4db597595e541fb4b7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing SQuAD-v2:   0%|          | 0/130319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f8577ae39143b28e7d52cc403f8218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing SQuAD-v2:   0%|          | 0/11873 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133921\n",
      "12351\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing SQuAD-v2 dataset (100 samples)...\")\n",
    "train_ds, val_ds = prepare_squad(tokenizer)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, collate_fn=default_data_collator)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, shuffle=False, collate_fn=default_data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:21:10.731322Z",
     "iopub.status.busy": "2025-11-02T11:21:10.731041Z",
     "iopub.status.idle": "2025-11-02T11:22:15.905927Z",
     "shell.execute_reply": "2025-11-02T11:22:15.905224Z",
     "shell.execute_reply.started": "2025-11-02T11:21:10.731299Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DeepSeek model with multi-GPU support...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede01ec4717341efa34c6fcfba53a944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a24fdf799142209706db40b57d6e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fa5a4f1b0840a79b063031747f8b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForQuestionAnswering were not initialized from the model checkpoint at deepseek-ai/deepseek-coder-1.3b-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight', 'transformer.embed_tokens.weight', 'transformer.layers.0.input_layernorm.weight', 'transformer.layers.0.mlp.down_proj.weight', 'transformer.layers.0.mlp.gate_proj.weight', 'transformer.layers.0.mlp.up_proj.weight', 'transformer.layers.0.post_attention_layernorm.weight', 'transformer.layers.0.self_attn.k_proj.weight', 'transformer.layers.0.self_attn.o_proj.weight', 'transformer.layers.0.self_attn.q_proj.weight', 'transformer.layers.0.self_attn.v_proj.weight', 'transformer.layers.1.input_layernorm.weight', 'transformer.layers.1.mlp.down_proj.weight', 'transformer.layers.1.mlp.gate_proj.weight', 'transformer.layers.1.mlp.up_proj.weight', 'transformer.layers.1.post_attention_layernorm.weight', 'transformer.layers.1.self_attn.k_proj.weight', 'transformer.layers.1.self_attn.o_proj.weight', 'transformer.layers.1.self_attn.q_proj.weight', 'transformer.layers.1.self_attn.v_proj.weight', 'transformer.layers.10.input_layernorm.weight', 'transformer.layers.10.mlp.down_proj.weight', 'transformer.layers.10.mlp.gate_proj.weight', 'transformer.layers.10.mlp.up_proj.weight', 'transformer.layers.10.post_attention_layernorm.weight', 'transformer.layers.10.self_attn.k_proj.weight', 'transformer.layers.10.self_attn.o_proj.weight', 'transformer.layers.10.self_attn.q_proj.weight', 'transformer.layers.10.self_attn.v_proj.weight', 'transformer.layers.11.input_layernorm.weight', 'transformer.layers.11.mlp.down_proj.weight', 'transformer.layers.11.mlp.gate_proj.weight', 'transformer.layers.11.mlp.up_proj.weight', 'transformer.layers.11.post_attention_layernorm.weight', 'transformer.layers.11.self_attn.k_proj.weight', 'transformer.layers.11.self_attn.o_proj.weight', 'transformer.layers.11.self_attn.q_proj.weight', 'transformer.layers.11.self_attn.v_proj.weight', 'transformer.layers.12.input_layernorm.weight', 'transformer.layers.12.mlp.down_proj.weight', 'transformer.layers.12.mlp.gate_proj.weight', 'transformer.layers.12.mlp.up_proj.weight', 'transformer.layers.12.post_attention_layernorm.weight', 'transformer.layers.12.self_attn.k_proj.weight', 'transformer.layers.12.self_attn.o_proj.weight', 'transformer.layers.12.self_attn.q_proj.weight', 'transformer.layers.12.self_attn.v_proj.weight', 'transformer.layers.13.input_layernorm.weight', 'transformer.layers.13.mlp.down_proj.weight', 'transformer.layers.13.mlp.gate_proj.weight', 'transformer.layers.13.mlp.up_proj.weight', 'transformer.layers.13.post_attention_layernorm.weight', 'transformer.layers.13.self_attn.k_proj.weight', 'transformer.layers.13.self_attn.o_proj.weight', 'transformer.layers.13.self_attn.q_proj.weight', 'transformer.layers.13.self_attn.v_proj.weight', 'transformer.layers.14.input_layernorm.weight', 'transformer.layers.14.mlp.down_proj.weight', 'transformer.layers.14.mlp.gate_proj.weight', 'transformer.layers.14.mlp.up_proj.weight', 'transformer.layers.14.post_attention_layernorm.weight', 'transformer.layers.14.self_attn.k_proj.weight', 'transformer.layers.14.self_attn.o_proj.weight', 'transformer.layers.14.self_attn.q_proj.weight', 'transformer.layers.14.self_attn.v_proj.weight', 'transformer.layers.15.input_layernorm.weight', 'transformer.layers.15.mlp.down_proj.weight', 'transformer.layers.15.mlp.gate_proj.weight', 'transformer.layers.15.mlp.up_proj.weight', 'transformer.layers.15.post_attention_layernorm.weight', 'transformer.layers.15.self_attn.k_proj.weight', 'transformer.layers.15.self_attn.o_proj.weight', 'transformer.layers.15.self_attn.q_proj.weight', 'transformer.layers.15.self_attn.v_proj.weight', 'transformer.layers.16.input_layernorm.weight', 'transformer.layers.16.mlp.down_proj.weight', 'transformer.layers.16.mlp.gate_proj.weight', 'transformer.layers.16.mlp.up_proj.weight', 'transformer.layers.16.post_attention_layernorm.weight', 'transformer.layers.16.self_attn.k_proj.weight', 'transformer.layers.16.self_attn.o_proj.weight', 'transformer.layers.16.self_attn.q_proj.weight', 'transformer.layers.16.self_attn.v_proj.weight', 'transformer.layers.17.input_layernorm.weight', 'transformer.layers.17.mlp.down_proj.weight', 'transformer.layers.17.mlp.gate_proj.weight', 'transformer.layers.17.mlp.up_proj.weight', 'transformer.layers.17.post_attention_layernorm.weight', 'transformer.layers.17.self_attn.k_proj.weight', 'transformer.layers.17.self_attn.o_proj.weight', 'transformer.layers.17.self_attn.q_proj.weight', 'transformer.layers.17.self_attn.v_proj.weight', 'transformer.layers.18.input_layernorm.weight', 'transformer.layers.18.mlp.down_proj.weight', 'transformer.layers.18.mlp.gate_proj.weight', 'transformer.layers.18.mlp.up_proj.weight', 'transformer.layers.18.post_attention_layernorm.weight', 'transformer.layers.18.self_attn.k_proj.weight', 'transformer.layers.18.self_attn.o_proj.weight', 'transformer.layers.18.self_attn.q_proj.weight', 'transformer.layers.18.self_attn.v_proj.weight', 'transformer.layers.19.input_layernorm.weight', 'transformer.layers.19.mlp.down_proj.weight', 'transformer.layers.19.mlp.gate_proj.weight', 'transformer.layers.19.mlp.up_proj.weight', 'transformer.layers.19.post_attention_layernorm.weight', 'transformer.layers.19.self_attn.k_proj.weight', 'transformer.layers.19.self_attn.o_proj.weight', 'transformer.layers.19.self_attn.q_proj.weight', 'transformer.layers.19.self_attn.v_proj.weight', 'transformer.layers.2.input_layernorm.weight', 'transformer.layers.2.mlp.down_proj.weight', 'transformer.layers.2.mlp.gate_proj.weight', 'transformer.layers.2.mlp.up_proj.weight', 'transformer.layers.2.post_attention_layernorm.weight', 'transformer.layers.2.self_attn.k_proj.weight', 'transformer.layers.2.self_attn.o_proj.weight', 'transformer.layers.2.self_attn.q_proj.weight', 'transformer.layers.2.self_attn.v_proj.weight', 'transformer.layers.20.input_layernorm.weight', 'transformer.layers.20.mlp.down_proj.weight', 'transformer.layers.20.mlp.gate_proj.weight', 'transformer.layers.20.mlp.up_proj.weight', 'transformer.layers.20.post_attention_layernorm.weight', 'transformer.layers.20.self_attn.k_proj.weight', 'transformer.layers.20.self_attn.o_proj.weight', 'transformer.layers.20.self_attn.q_proj.weight', 'transformer.layers.20.self_attn.v_proj.weight', 'transformer.layers.21.input_layernorm.weight', 'transformer.layers.21.mlp.down_proj.weight', 'transformer.layers.21.mlp.gate_proj.weight', 'transformer.layers.21.mlp.up_proj.weight', 'transformer.layers.21.post_attention_layernorm.weight', 'transformer.layers.21.self_attn.k_proj.weight', 'transformer.layers.21.self_attn.o_proj.weight', 'transformer.layers.21.self_attn.q_proj.weight', 'transformer.layers.21.self_attn.v_proj.weight', 'transformer.layers.22.input_layernorm.weight', 'transformer.layers.22.mlp.down_proj.weight', 'transformer.layers.22.mlp.gate_proj.weight', 'transformer.layers.22.mlp.up_proj.weight', 'transformer.layers.22.post_attention_layernorm.weight', 'transformer.layers.22.self_attn.k_proj.weight', 'transformer.layers.22.self_attn.o_proj.weight', 'transformer.layers.22.self_attn.q_proj.weight', 'transformer.layers.22.self_attn.v_proj.weight', 'transformer.layers.23.input_layernorm.weight', 'transformer.layers.23.mlp.down_proj.weight', 'transformer.layers.23.mlp.gate_proj.weight', 'transformer.layers.23.mlp.up_proj.weight', 'transformer.layers.23.post_attention_layernorm.weight', 'transformer.layers.23.self_attn.k_proj.weight', 'transformer.layers.23.self_attn.o_proj.weight', 'transformer.layers.23.self_attn.q_proj.weight', 'transformer.layers.23.self_attn.v_proj.weight', 'transformer.layers.3.input_layernorm.weight', 'transformer.layers.3.mlp.down_proj.weight', 'transformer.layers.3.mlp.gate_proj.weight', 'transformer.layers.3.mlp.up_proj.weight', 'transformer.layers.3.post_attention_layernorm.weight', 'transformer.layers.3.self_attn.k_proj.weight', 'transformer.layers.3.self_attn.o_proj.weight', 'transformer.layers.3.self_attn.q_proj.weight', 'transformer.layers.3.self_attn.v_proj.weight', 'transformer.layers.4.input_layernorm.weight', 'transformer.layers.4.mlp.down_proj.weight', 'transformer.layers.4.mlp.gate_proj.weight', 'transformer.layers.4.mlp.up_proj.weight', 'transformer.layers.4.post_attention_layernorm.weight', 'transformer.layers.4.self_attn.k_proj.weight', 'transformer.layers.4.self_attn.o_proj.weight', 'transformer.layers.4.self_attn.q_proj.weight', 'transformer.layers.4.self_attn.v_proj.weight', 'transformer.layers.5.input_layernorm.weight', 'transformer.layers.5.mlp.down_proj.weight', 'transformer.layers.5.mlp.gate_proj.weight', 'transformer.layers.5.mlp.up_proj.weight', 'transformer.layers.5.post_attention_layernorm.weight', 'transformer.layers.5.self_attn.k_proj.weight', 'transformer.layers.5.self_attn.o_proj.weight', 'transformer.layers.5.self_attn.q_proj.weight', 'transformer.layers.5.self_attn.v_proj.weight', 'transformer.layers.6.input_layernorm.weight', 'transformer.layers.6.mlp.down_proj.weight', 'transformer.layers.6.mlp.gate_proj.weight', 'transformer.layers.6.mlp.up_proj.weight', 'transformer.layers.6.post_attention_layernorm.weight', 'transformer.layers.6.self_attn.k_proj.weight', 'transformer.layers.6.self_attn.o_proj.weight', 'transformer.layers.6.self_attn.q_proj.weight', 'transformer.layers.6.self_attn.v_proj.weight', 'transformer.layers.7.input_layernorm.weight', 'transformer.layers.7.mlp.down_proj.weight', 'transformer.layers.7.mlp.gate_proj.weight', 'transformer.layers.7.mlp.up_proj.weight', 'transformer.layers.7.post_attention_layernorm.weight', 'transformer.layers.7.self_attn.k_proj.weight', 'transformer.layers.7.self_attn.o_proj.weight', 'transformer.layers.7.self_attn.q_proj.weight', 'transformer.layers.7.self_attn.v_proj.weight', 'transformer.layers.8.input_layernorm.weight', 'transformer.layers.8.mlp.down_proj.weight', 'transformer.layers.8.mlp.gate_proj.weight', 'transformer.layers.8.mlp.up_proj.weight', 'transformer.layers.8.post_attention_layernorm.weight', 'transformer.layers.8.self_attn.k_proj.weight', 'transformer.layers.8.self_attn.o_proj.weight', 'transformer.layers.8.self_attn.q_proj.weight', 'transformer.layers.8.self_attn.v_proj.weight', 'transformer.layers.9.input_layernorm.weight', 'transformer.layers.9.mlp.down_proj.weight', 'transformer.layers.9.mlp.gate_proj.weight', 'transformer.layers.9.mlp.up_proj.weight', 'transformer.layers.9.post_attention_layernorm.weight', 'transformer.layers.9.self_attn.k_proj.weight', 'transformer.layers.9.self_attn.o_proj.weight', 'transformer.layers.9.self_attn.q_proj.weight', 'transformer.layers.9.self_attn.v_proj.weight', 'transformer.norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32023, 2048)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " print(\"Loading DeepSeek model with multi-GPU support...\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "        device_map=\"cuda:0\",  # ✅ Shard across GPUs automatically\n",
    "    )\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-02T11:23:15.566Z",
     "iopub.execute_input": "2025-11-02T11:22:15.906879Z",
     "iopub.status.busy": "2025-11-02T11:22:15.906630Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning with Eq.1.3 Adaptive LoRA...\n",
      "\n",
      "=== Epoch 1/1 ===\n",
      "Computing BI importance (Eq.1.3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing BI importance:   0%|          | 1/500 [00:01<16:17,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] BI score stats → min=-3.994220e-07, max=1.500634e-04, mean=8.848093e-07\n",
      "\n",
      "=== BI Importance Scores & Adaptive Rank Allocation ===\n",
      "Layer Name                                                   |   BI Score |  Rank\n",
      "--------------------------------------------------------------------------------\n",
      "qa_outputs                                                   |   0.000150 |   517\n",
      "transformer.layers.2.self_attn.v_proj                        |   0.000001 |     2\n",
      "transformer.layers.2.self_attn.o_proj                        |   0.000001 |     2\n",
      "transformer.layers.1.self_attn.o_proj                        |   0.000000 |     1\n",
      "transformer.layers.1.self_attn.v_proj                        |   0.000000 |     1\n",
      "transformer.layers.0.self_attn.o_proj                        |   0.000000 |     1\n",
      "transformer.layers.0.self_attn.v_proj                        |   0.000000 |     1\n",
      "transformer.layers.8.self_attn.v_proj                        |   0.000000 |     1\n",
      "transformer.layers.8.self_attn.o_proj                        |   0.000000 |     1\n",
      "transformer.layers.5.mlp.down_proj                           |   0.000000 |     1\n",
      "transformer.layers.12.mlp.down_proj                          |   0.000000 |     1\n",
      "transformer.layers.5.mlp.gate_proj                           |   0.000000 |     1\n",
      "transformer.layers.11.self_attn.o_proj                       |   0.000000 |     1\n",
      "transformer.layers.11.self_attn.v_proj                       |   0.000000 |     1\n",
      "transformer.layers.7.self_attn.v_proj                        |   0.000000 |     1\n",
      "transformer.layers.7.self_attn.o_proj                        |   0.000000 |     1\n",
      "transformer.layers.14.mlp.down_proj                          |   0.000000 |     1\n",
      "transformer.layers.12.mlp.gate_proj                          |   0.000000 |     1\n",
      "transformer.layers.5.mlp.up_proj                             |   0.000000 |     1\n",
      "transformer.layers.21.self_attn.v_proj                       |   0.000000 |     1\n",
      "--------------------------------------------------------------------------------\n",
      "Displayed top 20 of 169 total layers.\n",
      "Patched 169 modules with LoRA adapters.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   1%|          | 45/5000 [00:55<1:41:14,  1.23s/it, avg_loss=6.04]"
     ]
    }
   ],
   "source": [
    "   \n",
    "print(\"Starting fine-tuning with Eq.1.3 Adaptive LoRA...\")\n",
    "fine_tune_lora_dynamic(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=\"cuda:0\",\n",
    "        total_R=516,      \n",
    "        tau=0.5,\n",
    "        epochs=3,        \n",
    "        lr=3e-5,\n",
    "        weight_decay=0.01,\n",
    "        max_batches_for_bi=1,\n",
    "        recompute_every=1,\n",
    "        fast_mode=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-02T11:23:15.567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_dir = \"./saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_path = os.path.join(save_dir, \"deepseek_eq13_qa_small.pt\")\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"\\n✅ Model saved successfully to: {save_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-02T11:23:15.567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    # Quick inference test\n",
    "model.eval()\n",
    "context = \"The Eiffel Tower is located in Paris and was completed in 1889.\"\n",
    "question = \"When was the Eiffel Tower completed?\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "start = torch.argmax(outputs.start_logits)\n",
    "end = torch.argmax(outputs.end_logits) + 1\n",
    "answer = tokenizer.decode(inputs[\"input_ids\"][0][start:end])\n",
    "print(f\"Predicted answer: {answer}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
